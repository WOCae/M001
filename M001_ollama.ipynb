{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83211fab",
   "metadata": {},
   "source": [
    "ollamaã®èµ·å‹•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b7099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ä¾å­˜ãƒ„ãƒ¼ãƒ«ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "!apt-get update && apt-get install -y zstd pciutils\n",
    "\n",
    "# 2. Ollamaã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# å…±é€šè¨­å®šï¼ˆã“ã“ã§ãƒ¢ãƒ‡ãƒ«åã‚’ä¸€æ‹¬ç®¡ç†ã—ã¾ã™ï¼‰\n",
    "# ä½¿ç”¨ã—ãŸã„ãƒ¢ãƒ‡ãƒ«åï¼ˆglm4, llama3, qwen2-vl ãªã©ï¼‰ã‚’ã“ã“ã«è¨˜è¿°\n",
    "MODEL_NAME = \"glm-4.7-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c8f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_ollama_server(model_name):\n",
    "    \"\"\"ã‚µãƒ¼ãƒãƒ¼ã‚’å†èµ·å‹•ã—ã€æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’æº–å‚™ã™ã‚‹\"\"\"\n",
    "    print(\"ğŸ”„ ã‚µãƒ¼ãƒãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆä¸­...\")\n",
    "    !pkill ollama\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # ã‚µãƒ¼ãƒãƒ¼ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§èµ·å‹•\n",
    "    subprocess.Popen([\"ollama\", \"serve\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    print(f\"â³ ãƒ¢ãƒ‡ãƒ« '{model_name}' ã‚’æº–å‚™ä¸­...\")\n",
    "    subprocess.run([\"ollama\", \"pull\", model_name])\n",
    "    \n",
    "    # æ¥ç¶šç¢ºèª\n",
    "    try:\n",
    "        res = requests.get(\"http://localhost:11434/api/tags\")\n",
    "        if res.status_code == 200:\n",
    "            models = [m['name'] for m in res.json()['models']]\n",
    "            print(f\"âœ… Ollama server is live! åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«: {models}\")\n",
    "            return True\n",
    "    except:\n",
    "        print(\"âŒ ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\")\n",
    "        return False\n",
    "\n",
    "# å®Ÿè¡Œ\n",
    "setup_ollama_server(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a303d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_vscode_tunnel():\n",
    "    \"\"\"VS Code Tunnelã‚’èµ·å‹•ã—ã€GitHubèªè¨¼URLã‚’è¡¨ç¤ºã™ã‚‹\"\"\"\n",
    "    # CLIã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "    !curl -Lk 'https://code.visualstudio.com/sha/download?build=stable&os=cli-alpine-x64' --output vscode_cli.tar.gz\n",
    "    !tar -xf vscode_cli.tar.gz\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸš€ VS Code Tunnel ã‚’èµ·å‹•ã—ã¾ã™ã€‚\")\n",
    "    print(\"è¡¨ç¤ºã•ã‚Œã‚‹URLã‹ã‚‰GitHubãƒ­ã‚°ã‚¤ãƒ³ã‚’è¡Œã„ã€ãƒ–ãƒ©ã‚¦ã‚¶ç‰ˆVS Codeã‚’é–‹ã„ã¦ãã ã•ã„ã€‚\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # ãƒˆãƒ³ãƒãƒ«èµ·å‹•\n",
    "    !./code tunnel --accept-server-license-terms --random-name --provider github\n",
    "\n",
    "# èµ·å‹•\n",
    "launch_vscode_tunnel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
